{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hepatitis_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['DIE_LIVE'] = df['DIE_LIVE'].replace(2,8)\n",
    "#df['DIE_LIVE'] = df['DIE_LIVE'].replace(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.405204</td>\n",
       "      <td>0.044164</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.260223</td>\n",
       "      <td>0.028391</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.074349</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.294890</td>\n",
       "      <td>0.293375</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.256506</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146431</td>\n",
       "      <td>0.294890</td>\n",
       "      <td>0.113398</td>\n",
       "      <td>0.399364</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.294890</td>\n",
       "      <td>0.113398</td>\n",
       "      <td>0.399364</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.294890</td>\n",
       "      <td>0.053628</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.618523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    0         1    2         3    4    5    6    7    8 ...   \\\n",
       "0           0  1.0  0.323944  1.0  0.000000  1.0  1.0  1.0  1.0  0.0 ...    \n",
       "1           1  1.0  0.605634  0.0  0.000000  1.0  0.0  1.0  1.0  0.0 ...    \n",
       "2           2  1.0  1.000000  0.0  1.000000  1.0  0.0  1.0  1.0  1.0 ...    \n",
       "3           3  1.0  0.338028  0.0  0.506494  0.0  1.0  1.0  1.0  1.0 ...    \n",
       "4           4  1.0  0.380282  0.0  1.000000  1.0  1.0  1.0  1.0  1.0 ...    \n",
       "5           5  1.0  0.380282  0.0  1.000000  1.0  1.0  1.0  1.0  1.0 ...    \n",
       "6           6  0.0  0.619718  0.0  0.000000  1.0  0.0  1.0  0.0  1.0 ...    \n",
       "7           7  1.0  0.225352  0.0  1.000000  1.0  1.0  1.0  1.0  1.0 ...    \n",
       "8           8  1.0  0.450704  0.0  1.000000  1.0  0.0  1.0  1.0  1.0 ...    \n",
       "\n",
       "    10   11   12   13        14        15        16        17        18   19  \n",
       "0  1.0  1.0  1.0  1.0  0.090909  0.219331  0.006309  0.441860  0.618523  0.0  \n",
       "1  1.0  1.0  1.0  1.0  0.077922  0.405204  0.044164  0.325581  0.618523  0.0  \n",
       "2  1.0  1.0  1.0  1.0  0.051948  0.260223  0.028391  0.441860  0.618523  0.0  \n",
       "3  1.0  1.0  1.0  1.0  0.051948  0.074349  0.059937  0.441860  0.800000  0.0  \n",
       "4  1.0  1.0  1.0  1.0  0.090909  0.294890  0.293375  0.441860  0.618523  0.0  \n",
       "5  1.0  1.0  1.0  1.0  0.077922  0.256506  0.022082  0.441860  0.750000  0.0  \n",
       "6  0.0  0.0  1.0  1.0  0.146431  0.294890  0.113398  0.399364  0.618523  0.0  \n",
       "7  1.0  1.0  1.0  1.0  0.090909  0.294890  0.113398  0.399364  0.618523  0.0  \n",
       "8  1.0  1.0  1.0  1.0  0.051948  0.294890  0.053628  0.534884  0.618523  0.0  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the features and outputs\n",
    "#x = np.array(df.loc[:,['AGE','SEX','STEROID','ANTIVIRAL','FATIGUE','MALAISE','ANOREXIA','LIVER_BIG','LIVER_FIRM','SPLEEN_PALPABLE','SPIDERS','ASCITES','VARICES','BILIRUBIN','ALK_PHOSPHATE','SGOT','ALBUMIN','PROTIME','HISTOLOGY']])\n",
    "#y = np.array(df.loc[:,['DIE_LIVE']])\n",
    "#print(y)\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the features and outputs\n",
    "#This cell is for the normailzed data\n",
    "x = np.array(df.loc[:,['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']])\n",
    "y = np.array(df.loc[:,['0']])\n",
    "#print(y)\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00652607 0.70096018 0.59335146 0.13887965 0.11119034 0.18194879\n",
      " 0.20490716 0.10693568 0.67658056 0.33240054 0.37830412 0.67749685\n",
      " 0.18278288 0.81435179 0.76206262 0.12265729 0.17860127 0.65886583\n",
      " 0.25338744]\n",
      "[-2.5954253   1.54995044  0.4847635  -0.35453896  0.9281094   0.67578134\n",
      " -0.40257324 -1.55486952 -1.03887831  1.53040588  1.50600227  0.59419843\n",
      "  1.35636077 -1.12753628  1.77907245  0.09488328  1.29468419  0.96254194\n",
      " -1.0301556 ]\n"
     ]
    }
   ],
   "source": [
    "#Assigning the weight values \n",
    "#for the input neurons\n",
    "w1 = np.random.rand(19)\n",
    "w2 = np.random.rand(19)\n",
    "w3 = np.random.rand(19)\n",
    "w4 = np.random.rand(19)\n",
    "\n",
    "#Assigning the bias values for the hidden layer neurons\n",
    "bh = np.random.rand(4)\n",
    "\n",
    "#Learning rate of the model\n",
    "lr = 0.001\n",
    "\n",
    "#for the output neuron \n",
    "w5 = np.random.rand(4)\n",
    "w6 = np.random.rand(4)\n",
    "#bias values for the output neurons\n",
    "bo = np.random.rand(2)\n",
    "\n",
    "\n",
    "#splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.17, random_state=700)\n",
    "\n",
    "[r,c] = X_train.shape\n",
    "e=0\n",
    "print(w1)\n",
    "epoch = 10001\n",
    "while(e<epoch):\n",
    "    for i in range(r):\n",
    "        s1=0\n",
    "        s2=0\n",
    "        s3=0\n",
    "        s4=0\n",
    "        for j in range(c):\n",
    "                s1+=w1[j]*X_train[i,j]\n",
    "                s2+=w2[j]*X_train[i,j]\n",
    "                s3+=w3[j]*X_train[i,j]\n",
    "                s4+=w4[j]*X_train[i,j]\n",
    "        s1+=bh[0]\n",
    "        s2+=bh[1]\n",
    "        s3+=bh[2]\n",
    "        s4+=bh[3]\n",
    "        out1=sigmoid(s1)\n",
    "        out2=sigmoid(s2)\n",
    "        out3=sigmoid(s3)\n",
    "        out4=sigmoid(s4)\n",
    "        s5=0\n",
    "        s6=0\n",
    "        #print(s1)\n",
    "        #progating to the output layer\n",
    "        s5+= ((out1*w5[0])+(out2*w5[1])+(out3*w5[2])+(out4*w5[3]))\n",
    "        s5+=bo[0]\n",
    "        out5=sigmoid(s5)\n",
    "        s6+=((out1*w6[0])+(out2*w6[1])+(out3*w6[2])+(out4*w6[3]))\n",
    "        s6+=bo[1]\n",
    "        out6=sigmoid(s6)\n",
    "        #calculating the delta value for the output neuron\n",
    "        if(y_train[i]==1.0):            #this one is for normalized data, for previous data, Do as needed\n",
    "            err5=out5*(1-out5)*(1-out5) #the first output neuron will give output 1 if the person lives, 0 if Dies\n",
    "            err6=out6*(1-out6)*(0-out6)\n",
    "        else:\n",
    "            err5=out5*(1-out5)*(0-out5) #the second output neuron will give output 0 if the person lives, 1 if Dies\n",
    "            err6=out6*(1-out6)*(1-out6)\n",
    "        #updating the weights of the output layer\n",
    "        w5[0] = w5[0] + (lr*err5*out1)\n",
    "        w5[1] = w5[1] + (lr*err5*out2)\n",
    "        w5[2] = w5[2] + (lr*err5*out3)\n",
    "        w5[3] = w5[3] + (lr*err5*out4)\n",
    "        bo[0]+= lr*err5\n",
    "        w6[0] = w6[0] + (lr*err6*out1)\n",
    "        w6[1] = w6[1] + (lr*err6*out2)\n",
    "        w6[2] = w6[2] + (lr*err6*out3)\n",
    "        w6[3] = w6[3] + (lr*err6*out4)\n",
    "        bo[1]+= lr*err6\n",
    "        #BackPropagating/Calculating the hidden layer delta values\n",
    "        err1=out1*(1-out1)*((w5[0]*err5)+(w6[0]*err6))\n",
    "        err2=out2*(1-out2)*((w5[1]*err5)+(w6[1]*err6))\n",
    "        err3=out3*(1-out3)*((w5[2]*err5)+(w6[2]*err6))\n",
    "        err4=out4*(1-out4)*((w5[3]*err5)+(w6[3]*err6))\n",
    "        #Updating the weights of the input layer\n",
    "        for j in range(c):\n",
    "            w1[j]+=(lr*err1*X_train[i,j])\n",
    "            w2[j]+=(lr*err2*X_train[i,j])\n",
    "            w3[j]+=(lr*err3*X_train[i,j])\n",
    "            w4[j]+=(lr*err4*X_train[i,j])\n",
    "        bh[0]+=lr*err1\n",
    "        bh[1]+=lr*err2\n",
    "        bh[2]+=lr*err3\n",
    "        bh[3]+=lr*err4\n",
    "    e+=1\n",
    "\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test\n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "y_pred1\n",
      "\n",
      "[0.7763184108409132, 0.9250295429868407, 0.9336612897530193, 0.18025231740329348, 0.9197219891609514, 0.415102716221352, 0.9180054556266185, 0.8718755187043564, 0.8908616095066484, 0.9283888286879042, 0.9337000023167088, 0.801876714323913, 0.9321556285124735, 0.9355017850735531, 0.92603591561543, 0.9356381586160967, 0.9097196897746985, 0.9240198774194378, 0.929556417670612, 0.9383482453345379, 0.9345884585008043, 0.9184332054820197, 0.6221112116689191, 0.9306882973069573, 0.9326458728184549, 0.17402812718622634, 0.9146885581041042]\n",
      "[0.2235228567365656, 0.0745718538123111, 0.06598010097961991, 0.8209457502682562, 0.07987924504411471, 0.5855304204515364, 0.08158615814355435, 0.1268672146252677, 0.10874655815285285, 0.07105078608862003, 0.06594387536942396, 0.19799146461416806, 0.06748528731917498, 0.0640893551520067, 0.07360676405600798, 0.06380853566541021, 0.08968746787143551, 0.07521056173347486, 0.0700594252004601, 0.061277836156017604, 0.06499123143095262, 0.08103931282739735, 0.3767175737462385, 0.06889523660118214, 0.06699543360962298, 0.8272243487670933, 0.08478169582818457]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model \n",
    "[r,c] = X_test.shape\n",
    "y_pred1 = []\n",
    "y_pred2 = []\n",
    "for i in range(r):\n",
    "    s1=0\n",
    "    s2=0\n",
    "    s3=0\n",
    "    s4=0\n",
    "    for j in range(c):\n",
    "            s1+=w1[j]*X_test[i,j]\n",
    "            s2+=w2[j]*X_test[i,j]\n",
    "            s3+=w3[j]*X_test[i,j]\n",
    "            s4+=w4[j]*X_test[i,j]\n",
    "    s1+=bh[0]\n",
    "    s2+=bh[1]\n",
    "    s3+=bh[2]\n",
    "    s4+=bh[3]\n",
    "\n",
    "    out1=sigmoid(s1)\n",
    "    out2=sigmoid(s2)\n",
    "    out3=sigmoid(s3)\n",
    "    out4=sigmoid(s4)\n",
    "    s5=0\n",
    "    s6=0\n",
    "    s5+=(out1*w5[0]+out2*w5[1]+out3*w5[2]+out4*w5[3])\n",
    "    s5+=bo[0]\n",
    "    out5=sigmoid(s5)\n",
    "    y_pred1.append(out5)\n",
    "    s6+=(out1*w6[0]+out2*w6[1]+out3*w6[2]+out4*w6[3])\n",
    "    s6+=bo[1]\n",
    "    out6=sigmoid(s6)\n",
    "    y_pred2.append(out6)\n",
    "\n",
    "print('Y_test\\n')\n",
    "print(y_test)\n",
    "print('y_pred1\\n')\n",
    "print(y_pred1)\n",
    "print(y_pred2)\n",
    "#print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for i in range(r):\n",
    "    y_pred1[i] = round(y_pred1[i])\n",
    "for i in range(r):\n",
    "    y_pred2[i] = round(y_pred2[i])\n",
    "\n",
    "y_pred3=[]    \n",
    "for i in range(r):\n",
    "    if(y_pred1[i]==0 and y_pred2[i]==1):\n",
    "        y_pred3.append(0)\n",
    "        print(i)\n",
    "    else:\n",
    "        y_pred3.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.89\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : %.2f'%accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  Misclassified samples out of a total of  27\n"
     ]
    }
   ],
   "source": [
    "count =0 \n",
    "for i in range(r):\n",
    "    if(y_pred3[i]==y_test[i]):\n",
    "        ;\n",
    "    else:\n",
    "        count+=1\n",
    "        \n",
    "print(count,' Misclassified samples out of a total of ',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model has 19 input layer neurons,  4 hidden layer neurons and 2 output layer neurons.\n",
    "### The model gives an Accuracy of approx. 88-92% and 2 misclassified samples on the testing data that is the 15% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vaii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
